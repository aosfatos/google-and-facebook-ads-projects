{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from time import sleep\n",
    "import re\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.rrule import rrule, WEEKLY, DAILY\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import Keys, ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.service import Service as FirefoxService\n",
    "from webdriver_manager.firefox import GeckoDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = Path('projects/deputados-nao-declaram-gastos-com-google-e-facebook')\n",
    "\n",
    "ad_library_main_page = Path(wd / 'ad-library-main-page')\n",
    "single_ad_pages = Path(wd / 'single-ad-pages')\n",
    "downloads = Path(wd / 'downloads')\n",
    "resultados = Path(wd / 'resultados')\n",
    "\n",
    "for folder in [single_ads_pages, ad_library_main_page, downloads, resultados]:\n",
    "    if not folder.exists():\n",
    "        folder.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gastos da Câmara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps_URL = 'https://www.camara.leg.br/cotas/Ano-2023.json.zip'\n",
    "exps_filename = 'expenses.zip'\n",
    "\n",
    "r = requests.get(exps_URL)\n",
    "\n",
    "with open(downloads / exps_filename, mode='wb') as f:\n",
    "    f.write(r.content)\n",
    "\n",
    "with ZipFile(downloads /exps_filename, 'r') as zip_f:\n",
    "    zip_f.extractall(downloads)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de Gastos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(downloads / 'Ano-2023.json', encoding='utf-8') as j:\n",
    "    parsed = json.loads(j.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(parsed['dados'])\n",
    "\n",
    "df = (\n",
    "    df[\n",
    "        # (df['descricao'] == 'DIVULGAÇÃO DA ATIVIDADE PARLAMENTAR.') &\n",
    "        (df['legislatura'] == 2023)\n",
    "    ]\n",
    "    .drop(\n",
    "        columns=[\n",
    "            'cpf', 'numeroCarteiraParlamentar', 'legislatura',\n",
    "            'siglaPartido', 'numeroSubCota', 'codigoLegislatura',\n",
    "            'numeroEspecificacaoSubCota', 'passageiro',\n",
    "            'trecho', 'parcela', 'datPagamentoRestituicao',\n",
    "            'ressarcimento', 'descricaoEspecificacao',\n",
    "            'restituicao', 'siglaUF', 'tipoDocumento'\n",
    "            ]\n",
    "        )\n",
    ")\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df['cnpj_basico'] = df['cnpjCPF'].str.replace('.', '', regex=False).apply(lambda x: x[:8])\n",
    "\n",
    "df['datetime'] = (\n",
    "        (\n",
    "            df['ano'].astype(str) +\n",
    "            '-' +\n",
    "            df['mes'].astype(str).str.zfill(2)\n",
    "        ).apply(lambda x: pd.to_datetime(x, format='%Y-%m'))\n",
    "    )\n",
    "\n",
    "df = df[df['datetime'] < (datetime.today() - timedelta(days=60))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df[df['fornecedor'] == 'GOOGLE BRASIL INTERNET LTDA']\n",
    ").to_csv(resultados / 'declaracoes-de-gastos-com-google.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anúncios no Facebook\n",
    "\n",
    "Não conseguimos encontrar uma maneira de buscar anúncios feitos na biblioteca de anúncios do Facebook a partir do nome ou de IDs de contas na plataforma.\n",
    "\n",
    "A saída encontrada foi a de visitar cada página, raspar os anúncios feitos pelos perfis e posteriormente raspar as informações dos anúncios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = (\n",
    "    webdriver\n",
    "    .Firefox(service=FirefoxService(\n",
    "        GeckoDriverManager()\n",
    "        .install()\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDs das páginas de pessoas políticas no Facebook. Coletadas manualmente.\n",
    "\n",
    "pages_id = [\n",
    "    '173698339802515', '865232070270799', '489383607761535',\n",
    "    '1731337420462273', '1526870777612230', '1947356288874816',\n",
    "    '1321564147955463', '107356795270257', '152534811624066',\n",
    "    '104157151228447', '1638752696387328', '691899611250247',\n",
    "    '1642363142681223', '286531148619744', '361989510562789',\n",
    "    '345829265488872', '143803862450980', '391477497562861',\n",
    "    '1507476039474128', '224968724875918', '112434351352176',\n",
    "    '239756803177345', '368704519884205', '103015684871449',\n",
    "    '529821053761365', '124307224406046', '924601577651630',\n",
    "    '1527572800822387', '266360393867344', '166001994065417',\n",
    "    '396626607095420', '100217516152889', '529741837114868',\n",
    "    '216474455105209', '334810013335023', '1395013197441419',\n",
    "    '358592104714583', '411754008869486', '272425403490751',\n",
    "    '113901773672666', '221371211998801', '206365432837539',\n",
    "    '611112112239401', '167306944111245', '781653925252644',\n",
    "    '1433103303568739', '1533303356759820', '815039985305536',\n",
    "    '410655005626777', '1526286600948051', '931215210253332',\n",
    "    '420265928063107', '201991609984528', '179856875529257',\n",
    "    '552636458116557', '393428077515241', '1082805205172897',\n",
    "    '103860934882269', '514558765355005', '225167147655939',\n",
    "    '201044363357878', '409540602424777', '220778897969256',\n",
    "    '249383531739005', '695358380551267', '133602516654912',\n",
    "    '111949165566730', '332870466782583', '217423271714827',\n",
    "    '212423668965384', '122923285036030', '458048987893303',\n",
    "    '266651300126832', '721618744570005', '237597346269787',\n",
    "    '127139487368866', '580813708692882', '102088129018202',\n",
    "    '1035223423186579', '124002814371381', '286648849567',\n",
    "    '154086204688099', '193185607843864', '223832637675564',\n",
    "    '191512767645241', '428795217537762', '547530398646435',\n",
    "    '182235818872744', '100261572206297', '650190518395498',\n",
    "    '1054901897864467', '104530757861973', '123097244540886',\n",
    "    '842245655790289', '102753402027906', '699693400101917',\n",
    "    '205362089591468', '345425238826528', '659203737425877',\n",
    "    '117903068817531', '2042050096056582', '646292118914142',\n",
    "    '106376318992146', '140347022821700', '1441794469233984',\n",
    "    '1695544247372940', '775240779164982', '1191229370929329',\n",
    "    '272809098799', '851328134910897', '314213892042373',\n",
    "    '1450940791842660', '156499414480143', '136344939876101',\n",
    "    '660410357307599', '177115472342855', '1164910073641031',\n",
    "    '533495260042236', '102343683293212', '301814029885718',\n",
    "    '187682584611376', '564150546986457', '158198544337175',\n",
    "    '517712008679531', '329948620416635', '471144916255739',\n",
    "    '824390270907057', '765667336867771', '301106093563904',\n",
    "    '278887206056242', '575472512602115', '390501545079417',\n",
    "    '191591598062172', '102363272346398', '223383744823290',\n",
    "    '114407660269758', '208610802492299', '394517827279852',\n",
    "    '222639301175182', '212265828905225', '250817031788413',\n",
    "    '508569109204694', '680238528731583', '552483638152177',\n",
    "    '104486751876738', '364253843645006', '835813059780644',\n",
    "    '217451785552263', '1931989763744839', '251489518948731',\n",
    "    '155201831260401', '328393683976480', '110198205136477',\n",
    "    '496443053731900', '227403640631475', '130558143745099',\n",
    "    '520798404655508', '169743843175117', '1378617549025463',\n",
    "    '405401689514244', '1401978510018003', '782277955151459',\n",
    "    '518031775303071', '833053646745836', '678761768950811',\n",
    "    '1619570641615465', '1414776178738297', '620314628044090',\n",
    "    '108143861587898', '176976939109000', '273642106068512',\n",
    "    '1433929133492494', '200263040068985', '238761896484083',\n",
    "    '433519783479725', '462223517218816', '158894974200303',\n",
    "    '420875917999748', '861928933853138', '397405070321390',\n",
    "    '340186179736898', '555803774486872', '245784392128312',\n",
    "    '632161500194120', '263563620333111', '953514998164299',\n",
    "    '687008454694990', '405696379766191', '486914985073732',\n",
    "    '1385505868350890', '578898368860170', '206019209573311',\n",
    "    '142099522556207', '157982450937286', '174471285940778',\n",
    "    '1142941029175690', '1501236886772782', '401673676620654',\n",
    "    '656965247684115', '225122704193171', '424808937641023',\n",
    "    '174217422747805', '274527822566791', '1720125068073321',\n",
    "    '729392980520143', '1463458067229810', '235356953965179',\n",
    "    '1460558354166610', '194032184000941', '364042537032048',\n",
    "    '457224910969875', '801126203398977', '291482090931929']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime(2023, 1, 1)\n",
    "day_list = rrule(freq=DAILY, dtstart=start_date, until=datetime.now())\n",
    "\n",
    "days = []\n",
    "for start_date in day_list:\n",
    "    days.append((start_date, start_date + timedelta(days=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_files = [file.name for file in ad_library_main_page.glob('*.html')]\n",
    "\n",
    "for page_id in pages_id:\n",
    "    for day_n, day in enumerate(days):\n",
    "        start_date = day[0].strftime('%Y-%m-%d')\n",
    "        end_date = day[1].strftime('%Y-%m-%d')\n",
    "\n",
    "        url = f'https://www.facebook.com/ads/library/?active_status=all&ad_type=all&country=ALL&view_all_page_id={page_id}&sort_data[direction]=desc&sort_data[mode]=relevancy_monthly_grouped&start_date[min]={start_date}&start_date[max]={end_date}&search_type=page&media_type=all'\n",
    "        filename = f'{page_id}_{day_n}.html'\n",
    "\n",
    "        if filename not in saved_files:\n",
    "            driver.get(url)\n",
    "            for i in range(20):\n",
    "                sleep(0.5)\n",
    "                ActionChains(driver).send_keys(Keys.PAGE_DOWN).perform()\n",
    "                ActionChains(driver).send_keys(Keys.END).perform()\n",
    "            with open(ad_library_main_page / filename, mode='w', encoding='utf-8') as f:\n",
    "                f.write(driver.page_source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_ads_ids(soup):\n",
    "    ads_id = []\n",
    "\n",
    "    for i in soup.find_all('div'):\n",
    "        if 'Identificação' in i.text:\n",
    "            if len(i.text.split()) == 2:\n",
    "                ad_id = i.text.split()[-1]\n",
    "                ads_id.append(ad_id)\n",
    "    \n",
    "    ads_id = list(set(ads_id))\n",
    "    \n",
    "    return ads_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_collected = [file.name for file in single_ads_pages.glob('*.html')]\n",
    "\n",
    "for file in ad_library_main_page.glob('*.html'):\n",
    "    ads_in_file = []\n",
    "\n",
    "    with open(file) as ad_catalogue:\n",
    "        soup = bs(ad_catalogue.read(), 'html.parser')\n",
    "        ads_in_file.extend(get_all_ads_ids(soup))\n",
    "    \n",
    "    for ad_id in ads_in_file:\n",
    "        filename = f'{ad_id}.html'\n",
    "        if filename not in ads_collected:\n",
    "            sleep(3)\n",
    "            driver.get(f'https://www.facebook.com/ads/library/?id={ad_id}')\n",
    "            sleep(5)\n",
    "            soup = bs(driver.page_source, 'html.parser')\n",
    "            modal = soup.find('div', {'aria-label': 'Modal for the deep link ad'})\n",
    "            with open(single_ad_pages / filename, mode='w', encoding='utf-8') as f:\n",
    "                f.write(modal.contents[0].__str__())\n",
    "                \n",
    "                # Atualiza os ads coletados somente quando um novo é salvo.\n",
    "                ads_collected = [file.name for file in single_ad_pages.glob('*.html')]\n",
    "    \n",
    "    os.rename(file, ad_library_main_page / f'{file.stem}.old')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html(soup):\n",
    "    def get_ad_owner(soup):\n",
    "        try:\n",
    "            ad_owner = (\n",
    "                soup\n",
    "                .find('img')\n",
    "                ['alt']\n",
    "            )\n",
    "        except TypeError:\n",
    "            ad_owner = (\n",
    "                soup\n",
    "                .find('a')\n",
    "                .text\n",
    "            )\n",
    "        return ad_owner\n",
    "    \n",
    "    def get_ad_id(soup):\n",
    "        ad_string = (\n",
    "            re.findall(\n",
    "                string=soup.text,\n",
    "                pattern='Identificação: \\d{6,}'\n",
    "                )\n",
    "                )[0]\n",
    "        ad_id = ad_string.split(':')[-1].strip()\n",
    "        return ad_id\n",
    "\n",
    "    def get_impressions_count(soup):\n",
    "        for e in reversed(soup.find_all('div')):\n",
    "            if 'Impressões' in e.text:\n",
    "                impressions = unicodedata.normalize('NFKD', e.text)\n",
    "                break\n",
    "        if '<1 mil' in impressions:\n",
    "            lower_impressions, upper_impressions = (0, 1000)\n",
    "        elif '>1 mi' in impressions:\n",
    "            lower_impressions, upper_impressions = (1_000_000, None)\n",
    "        else:\n",
    "            impressions = (\n",
    "                impressions\n",
    "                .split(':')[-1]\n",
    "                .strip()\n",
    "                .replace(' mil', '000')\n",
    "                .replace(' mi', '000000')\n",
    "                )\n",
    "            lower_impressions, upper_impressions = impressions.split(' a ')\n",
    "\n",
    "        return lower_impressions, upper_impressions\n",
    "\n",
    "    def get_spent_value(soup):\n",
    "        for e in reversed(soup.find_all('div')):\n",
    "            if 'Valor gasto' in e.text:\n",
    "                spent_value = unicodedata.normalize('NFKD', e.text)\n",
    "                break\n",
    "        \n",
    "        spent_value = (\n",
    "            spent_value\n",
    "            .split(':')[-1]\n",
    "            .strip()\n",
    "            .replace('R$', '')\n",
    "            )\n",
    "        lower_spent_value, upper_spent_value = spent_value.split(' a ')\n",
    "\n",
    "        return int(lower_spent_value), int(upper_spent_value)\n",
    "\n",
    "    def get_spent_value(soup):\n",
    "        for e in reversed(soup.find_all('div')):\n",
    "            if 'Valor gasto' in e.text:\n",
    "                spent_value = unicodedata.normalize('NFKD', e.text)\n",
    "                break\n",
    "        if '<R$100' in spent_value:\n",
    "            lower_spent_value, upper_spent_value = 0, 100\n",
    "\n",
    "        else:\n",
    "            spent_value = (\n",
    "                spent_value\n",
    "                .split(':')[-1]\n",
    "                .strip()\n",
    "                .replace('R$', '')\n",
    "                .replace(',5 mil', '500')\n",
    "                .replace(' mil', '000')\n",
    "                )\n",
    "            lower_spent_value, upper_spent_value = spent_value.split(' a ')\n",
    "\n",
    "        return int(lower_spent_value), int(upper_spent_value)\n",
    "    \n",
    "    def get_publication_range(soup):\n",
    "        def format_date(date):\n",
    "            replace_map = {\n",
    "                'jan': '01', 'fev': '02', 'mar': '03',\n",
    "                'abr': '04', 'mai': '05', 'jun': '06',\n",
    "                'jul': '07', 'ago': '08', 'set': '09',\n",
    "                'out': '10',  'nov': '11', 'dez': '12'\n",
    "                }\n",
    "            day, month, year = date.lower().split('/')\n",
    "            day = day.zfill(2)\n",
    "            month = replace_map[month]\n",
    "            date = '/'.join([day, month, year])\n",
    "            return date\n",
    "\n",
    "        months = [\n",
    "            ' jan ', ' fev ', ' mar ', ' abr ',\n",
    "            ' mai ', ' jun ', ' jul ', ' ago ', ' set ',\n",
    "            ' out ', ' nov ', ' dez '\n",
    "            ]\n",
    "        for e in reversed(soup.find_all('div')):\n",
    "            if any (month in e.text for month in months):\n",
    "                if re.search(string=e.text, pattern='\\d{1,2} de \\w{3} de \\d{4}'):\n",
    "                    publication_range = (\n",
    "                        e.text\n",
    "                        .replace(' de ', '/')\n",
    "                        )\n",
    "                    break\n",
    "        \n",
    "        if 'Veiculação iniciada' in publication_range:\n",
    "            start_date = publication_range.replace('Veiculação iniciada em ', '')\n",
    "            start_date = format_date(start_date)\n",
    "            end_date = None\n",
    "        \n",
    "        else:\n",
    "            start_date, end_date = publication_range.split(' a ')\n",
    "            start_date = format_date(start_date)\n",
    "            end_date = format_date(end_date)\n",
    "        \n",
    "        return start_date, end_date\n",
    "\n",
    "    ad_id = get_ad_id(soup)\n",
    "    try:\n",
    "        ad_owner = get_ad_owner(soup)\n",
    "        lower_impressions, upper_impressions = get_impressions_count(soup)\n",
    "        lower_spent, upper_spent = get_spent_value(soup)\n",
    "        available_date_min, available_date_max = get_publication_range(soup)\n",
    "    except UnboundLocalError:\n",
    "        print(ad_id)\n",
    "        ad_owner = None\n",
    "        lower_impressions = None\n",
    "        upper_impressions = None\n",
    "        lower_spent = None\n",
    "        upper_spent = None\n",
    "        available_date_min = None\n",
    "        available_date_max = None\n",
    "\n",
    "    info = {\n",
    "        'ad_URL': 'https://www.facebook.com/ads/library/?id=' + ad_id,\n",
    "        'ad_id': ad_id,\n",
    "        'ad_owner': ad_owner,\n",
    "        'lower_impressions_range': lower_impressions,\n",
    "        'upper_impressions_range': upper_impressions,\n",
    "        'lower_spent_range_BRL': lower_spent,\n",
    "        'upper_spent_range_BRL': upper_spent,\n",
    "        'available_date_min': available_date_min,\n",
    "        'available_date_max': available_date_max\n",
    "    }\n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = []\n",
    "for file in single_ads_pages.glob('*.html'):\n",
    "    with open(file, mode='r', encoding='utf8') as f:\n",
    "        html_content = f.read()\n",
    "        soup  = bs(html_content, 'html.parser')\n",
    "        parsed = parse_html(soup)\n",
    "        infos.append(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_facebook = pd.DataFrame(infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_facebook.to_csv(resultados / 'ads-no-facebook-de-congressistas-2023.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aosfatos-work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
